---
title: select、poll、epoll
tags: 操作系统
category: CS大学生必备
date: 2020/04/05 17:42
---

select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。**但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的**，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。 

epoll跟select都能提供多路I/O复用的解决方案。在现在的Linux内核里有都能够支持，其中epoll是Linux所特有，而select则应该是POSIX所规定，一般操作系统均有实现。

<font size=4>

# select

**时间复杂度：**O(n)

它仅仅知道有I/O事件发生了，却并不知道是哪几个流（可能有一个，多个，甚至全部），我们只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。所以**select具有O(n)的无差别轮询复杂度**，同时处理的流越多，无差别轮询时间就越长。

## 缺点

select本质上是通过设置或者检查存放**fd(文件描述符)**标志位的数据结构来进行下一步处理。这样所带来的缺点是：

（1）单个进程可监视的fd数量被限制，即能监听端口的大小有限：

一般来说这个数目和系统内存关系很大，具体数目可以cat /proc/sys/fs/file-max察看。32位机默认是1024个。64位机默认是2048.
（2）对socket进行扫描时是线性扫描，即采用轮询的方法，效率较低：

当套接字比较多的时候，每次select()都要通过遍历FD_SETSIZE个Socket来完成调度,不管哪个Socket是活跃的,都遍历一遍。这会浪费很多CPU时间。如果能给套接字注册某个回调函数，当他们活跃时，自动完成相关操作，那就避免了轮询，这正是epoll与kqueue做的。
（3）需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大。

# poll

**时间复杂度:**O(n)

poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。这个过程经历了多次无谓的遍历。**但是它没有最大连接数的限制**，原因是它是基于链表来存储的.

## 缺点

（1）大量的fd的数组被整体复制于用户态和内核地址空间之间，而不管这样的复制是不是有意义；

（2）poll还有一个特点是“水平触发”，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd。

# epoll

**时间复杂度:**O(1)

**epoll可以理解为event poll**，不同于忙轮询和无差别轮询，epoll会把哪个流发生了怎样的I/O事件通知我们。所以我们说epoll实际上是**事件驱动（每个事件关联上fd）**的，此时我们对这些流的操作都是有意义的。**（复杂度降低到了O(1)）**

epoll支持水平触发和边缘触发，最大的特点在于边缘触发，它只告诉进程哪些fd刚刚变为就需态，并且只会通知一次。还有一个特点是，epoll使用“事件”的就绪通知方式，通过epoll_ctl注册fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd，epoll_wait便可以收到通知。

## 优点

（1）没有最大并发连接的限制，能打开的fd的上限远大于1024（1G的内存上能监听约10万个端口）
（2）效率提升，不是轮询的方式，不会随着fd数目的增加效率下降。只有活跃可用的fd才会调用callback函数，即epoll最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，epoll的效率就会远远高于select和poll。
（3）内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递，即epoll使用mmap减少复制开销。

 内核（kernel）利用文件描述符（file descriptor）fd来访问文件。文件描述符是非负整数。打开现存文件或新建文件时，内核会返回一个文件描述符。读写文件也需要使用文件描述符来指定待读写的文件。

<font size=4>

## epoll的主要机制

epoll主要解决的问题：I/O多路复用

epoll三大关键要素：mmap、红黑树、链表

epoll三大主要函数：epoll_create，epoll_ctl，epoll_wait

## epoll实现过程：

整体流程：

首先epoll_create建立一个epoll对象。参数是内核保证能够正确处理的最大句柄数，多余这个最大数时内核不保证效果。

epoll_ctl可以操作上面建立的epoll，例如，将刚建立的socket加入到epoll中让其监控，或者把epoll正在监控的某个socket句柄移出epoll。

epoll_wait在调用时，在给定的timeout内，当在监控的所有句柄有事件发生时，返回用户态的进程。

详细过程：

```c++
# 创建并初始化epoll

int epoll_create(int size); 

# 处理epoll内socket

int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);

# 从epoll内取出事件

int epoll_wait(int epfd, struct epoll_event *events,int maxevents, int timeout);
```



1.首先在epoll_create建立后，内核在内核态开始存储要监控的句柄，在内核里，一切皆文件，所以epoll向内核注册了一个文件系统，用于存储被监控的socket。当调用epoll_create时，就会在这个虚拟的epoll文件系统里创建一个file结点，并且只服务于epoll。

2.epoll在被内核初始化时，同时会开辟epoll自己的告诉内核cache区，用于安置每一个想要监控的socket，这些socket会以红黑树的形式保存在内核cache里。在这个内核高速cache区，就是建立连续的物理内存页，然后在之上建立slab层。简单说，就是物理上分配好想要的size的内存对象，每次使用时都是使用空闲的已经分配好的对象。

3.每次调用epoll_ctl只是在往内核的数据结构里塞入新的socket句柄。如果增加socket句柄，则检查红黑树中是否存在，存在立即返回，不存在则添加，然后想内核注册回调函数，用于当中断事件来临时向准备就绪链表中插入数据。

4.epoll的高效在于，当调用epoll_ctl往里面塞入百万个句柄时，epoll_wait仍然可以飞快的返回，并有效的将发生事件的句柄给用户。由于在调用epoll_create时，内核处理在epoll文件系统里建立了file节点，在内核cache里建立红黑树用于存储epoll_ctl传来的socket外，还会建立一个list链表，用于存储准备就绪的事件。

5.当执行epoll_ctl时，除了把socket放到epoll文件系统的file对象对应的红黑树之外，还会给内核中断处理程序注册一个回调函数，告诉内核，如果这个句柄的中断到了，放到准备就绪list链表里。所以，当一个socket上有数据了，内核把网卡上数据copy到内核中后就把socket插入到准备就绪链表中。

6.当epoll_wait调用时，仅仅观察这个list链表里有没有数据即可，有数据返回，没有就sleep，等到timeout时间到后即使链表没有数据也返回。

7.通常情况下要监控百万计的句柄，但是一次只返回少量准备就绪的句柄，所以epoll_wait仅需要从内核态copy少量的句柄到用户态而已。

 

## epoll中的数据结构：

1.mmap：

epoll通过内核与用户空间mmap同一块内存。mmap将用户空间的一块地址和内核空间的一块地址同时映射到相同的一块物理内存地址，使得这块物理内存对内核和用户均可见，减少用户和内核态之间的数据交换。内核可以直接看到epoll监听的句柄，效率更高。

2.红黑树：

红黑树将存储epoll所监听的所有套接字。mmap出来的内存在epoll上采用红黑树去存储所有的套接字，当添加或者删除一个套接字时(epoll_ctl），都在红黑树上处理，时间复杂度O(logN)

3.rdlist链表：

通过epoll_ctl函数添加进来的事件都会被放到红黑树的某个节点内。当事件添加进来的时候，该事件都会与相应的设备（网卡）驱动程序建立回调关系，当相应的事件发生后，就会调用这个回调函数(ep_poll_callbac)，这个回调函数其实就是把这个事件添加到rdlist这个双向链表中。一旦有事件发生，epoll就会将该事件添加到双向链表中。当调用epoll_wait时，epoll_wait只需要检查rdlist双向链表中是否存在注册事件。


学习链接：https://baijiahao.baidu.com/s?id=1641172494287388070&wfr=spider&for=pc

# 区别总结

1、支持一个进程所能打开的最大连接数

|        |                                                              |
| ------ | ------------------------------------------------------------ |
| select | 单个进程所能打开的最大连接数有FD_SETSIZE宏定义，其大小是32个整数的大小（在32位的机器上，大小就是32\*32，同理64位机器上FD_SETSIZE为32\*64），当然我们可以对进行修改，然后重新编译内核，但是性能可能会受到影响，这需要进一步的测试。 |
| poll   | poll本质上和select没有区别，但是它没有最大连接数的限制，原因是它是基于链表来存储的 |
| epoll  | 虽然连接数有上限，但是很大，1G内存的机器上可以打开10万左右的连接，2G内存的机器可以打开20万左右的连接 |

2、fd剧增后带来的IO效率问题

|        |                                                              |
| ------ | ------------------------------------------------------------ |
| select | 因为每次调用时都会对连接进行线性遍历，所以随着FD的增加会造成遍历速度慢的“线性下降性能问题”。 |
| poll   | 因为每次调用时都会对连接进行线性遍历，所以随着FD的增加会造成遍历速度慢的“线性下降性能问题”。 |
| epoll  | 因为epoll内核中实现是根据每个fd上的callback()函数来实现的，只有活跃的socket才会主动调用callback()，所以在活跃socket较少的情况下，使用epoll没有前面两者的线性下降的性能问题，但是所有socket都很活跃的情况下，可能会有性能问题。 |

3、 消息传递方式

|        |                                                  |
| ------ | ------------------------------------------------ |
| select | 内核需要将消息传递到用户空间，都需要内核拷贝动作 |
| poll   | 内核需要将消息传递到用户空间，都需要内核拷贝动作 |
| epoll  | 通过内核和用户空间共享一块内存来实现的。         |



4、总结：

综上，在选择select，poll，epoll时要根据具体的使用场合以及这三种方式的自身特点：

1、表面上看epoll的性能最好，但是在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调。

2、select低效是因为每次它都需要轮询。但低效也是相对的，视情况而定，也可通过良好的设计改善