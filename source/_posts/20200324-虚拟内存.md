---
title: 虚拟内存
tags: 操作系统
category: CS大学生必备
date: 2020/03/24 20:59
---



**1、对于CPU来说，它的目标存储器是物理内存，使用cache做物理内存的缓存**

**2、对于虚拟内存来说，它的目标存储器是磁盘空间，使用磁盘做物理内存的缓存**

<!--more-->

<font size=4>

## 虚拟内存与物理内存

操作系统有虚拟内存与物理内存的概念。在很久以前，还没有虚拟内存概念的时候，程序寻址用的都是物理地址。程序能寻址的范围是有限的，这取决于CPU的地址线条数。比如在32位平台下，寻址的范围是2^32也就是4G。并且这是固定的，如果没有虚拟内存，且每次开启一个进程都给4G的物理内存，就可能会出现很多问题：

- 因为我的物理内存时有限的，当有多个进程要执行的时候，都要给4G内存，很显然你内存小一点，这很快就分配完了，于是没有得到分配资源的进程就只能等待。当一个进程执行完了以后，再将等待的进程装入内存。这种频繁的装入内存的操作是很没效率的
- 由于指令都是直接访问物理内存的，那么我这个进程就可以修改其他进程的数据，甚至会修改内核地址空间的数据，这是我们不想看到的
- 因为内存时随机分配的，所以程序运行的地址也是不正确的。

于是针对上面会出现的各种问题，虚拟内存就出来了（CPU的地址线可以直接进行寻址的内存空间大小）。

- 在上面进程分配资源介绍过一个进程运行时都会得到4G的虚拟内存。这个虚拟内存你可以认为，每个进程都认为自己拥有4G的空间，这只是每个进程认为的，**但是实际上，在虚拟内存对应的物理内存上，可能只对应的一点点的物理内存，实际用了多少内存，就会对应多少物理内存。**
- 进程得到的这4G虚拟内存是一个连续的地址空间（这也只是进程认为），而实际上，它通常是被分隔成多个物理内存碎片，还有一部分存储在外部磁盘存储器上，在需要时进行数据交换。

进程开始要访问一个地址，它可能会经历下面的过程

1. 每次我要访问地址空间上的某一个地址，都需要把地址翻译为实际物理内存地址
2. 所有进程共享这整一块物理内存，每个进程只把自己目前需要的虚拟地址空间映射到物理内存上
3. 进程需要知道哪些地址空间上的数据在物理内存上，哪些不在（可能这部分存储在磁盘上），还有在物理内存上的哪里，这就需要通过页表来记录
4. 页表的每一个表项分两部分，第一部分记录此页是否在物理内存上，第二部分记录物理内存页的地址（如果在的话）
5. 当进程访问某个虚拟地址的时候，就会先去看页表，如果发现对应的数据不在物理内存上，就会发生缺页异常
6. 缺页异常的处理过程，操作系统立即阻塞该进程，并将硬盘里对应的页换入内存，然后使该进程就绪，如果内存已经满了，没有空地方了，那就找一个页覆盖，至于具体覆盖的哪个页，就需要看操作系统的页面置换算法是怎么设计的了。

关于虚拟内存与物理内存的联系，下面这张图可以帮助我们巩固。

![3.png](https://i.loli.net/2020/05/05/9fYSpFzAlqwDsQu.png)

页表的工作原理如下图

![3.png](https://i.loli.net/2020/05/05/BYtPCg3VNeHhl7d.png)

1. 我们的cpu想访问虚拟地址所在的虚拟页(VP3)，根据页表，找出页表中第三条的值,判断有效位。 如果有效位为1，DRMA缓存命中，根据物理页号，找到物理页当中的内容，返回。
2. 若有效位为0，参数缺页异常，调用内核缺页异常处理程序。内核通过页面置换算法选择一个页面作为被覆盖的页面，将该页的内容刷新到磁盘空间当中。然后把VP3映射的磁盘文件缓存到该物理页上面。然后页表中第三条，有效位变成1，第二部分存储上了可以对应物理内存页的地址的内容。
3. 缺页异常处理完毕后，返回中断前的指令，重新执行，此时缓存命中，执行1。
4. 将找到的内容映射到告诉缓存当中，CPU从告诉缓存中获取该值，结束。

**再来总结一下虚拟内存是怎么工作的**

- 当每个进程创建的时候，内核会为进程分配4G的虚拟内存，当进程还没有开始运行时，这只是一个内存布局。实际上并不立即就把虚拟内存对应位置的程序数据和代码（比如.text .data段）拷贝到物理内存中，只是建立好虚拟内存和磁盘文件之间的映射就好（叫做存储器映射）。这个时候数据和代码还是在磁盘上的。当运行到对应的程序时，进程去寻找页表，发现页表中地址没有存放在物理内存上，而是在磁盘上，于是发生缺页异常，于是将磁盘上的数据拷贝到物理内存中。
- 另外在进程运行过程中，要通过malloc来动态分配内存时，也只是分配了虚拟内存，即为这块虚拟内存对应的页表项做相应设置，当进程真正访问到此数据时，才引发缺页异常。
- 可以认为虚拟空间都被映射到了磁盘空间中（事实上也是按需要映射到磁盘空间上，通过mmap，mmap是用来建立虚拟空间和磁盘空间的映射关系的）



**利用虚拟内存机制的优点 **

- 既然每个进程的内存空间都是一致而且固定的（32位平台下都是4G），所以链接器在链接可执行文件时，可以设定内存地址，而不用去管这些数据最终实际内存地址，这交给内核来完成映射关系
- 当不同的进程使用同一段代码时，比如库文件的代码，在物理内存中可以只存储一份这样的代码，不同进程只要将自己的虚拟内存映射过去就好了，这样可以节省物理内存
- 在程序需要分配连续空间的时候，只需要在虚拟内存分配连续空间，而不需要物理内存时连续的，实际上，往往物理内存都是断断续续的内存碎片。这样就可以有效地利用我们的物理内存。
  

## 名词解释

**虚拟地址(virtual address)：**相对物理地址来说的概念，不真实存在的

**物理地址(physical address)：**真实存在的，和物理内存关联的

**页表(page table)：**管理虚拟内存页和物理内存页映射和缓存状态的数据结构，存在于主存中。

**页表条目(page table entry PTE)：**是构成页表的基本元素，是索引号为虚拟页号、值为物理页号的数组

**地址翻译：**将虚拟地址映射成物理地址的过程

**页(page)：**和存储里块一样，类似的单位；虚拟内存中使用页(**page**)来表示块

**虚拟页(VP)：**虚拟地址空间划分为多个固定大小的虚拟页

**物理页(PP)：**物理地址空间划分为多个固定大小的物理页

**页表基地址寄存器（PTBR）：**CPU有一个专门的页表基地址寄存器，指向当前页表的基地址

**翻译后备缓冲区（TLB）：**一个用来缓存页表条目PTE的硬件设备

**MMU(Memory Management Unit)：**内存管理单元，CPU中含有的硬件，将虚拟地址转换为物理地址,它包含两个部件，一个是分段部件，一个是分页部件。

## 早期内存分配机制

​       进程必须一次全部加载到内存中，方可运行。当进程很大，就无法运行。而且多道进程运行时，内存不足容纳所有进程，导致多道程序性能下降。

![1.jpg](https://i.loli.net/2020/04/18/iM3SlrvEcPeqNg6.jpg)

​        例如一台计算机有128M内存，A进程需要10M内存，B进程需要100M内存；操作系统会先将内存中的前 10M 分配给程序 A ，接着再从内存中剩余的 118M 中划分出 110M 分配给程序 B ；如果这时候又运行了需要20M程序 C，系统只剩下 8M 的空间可供使用，此时系统必须在已运行的程序中选择一个将该程序的数据暂时拷贝到硬盘上，释放出部分空间来供程序 C 使用，然后再将程序 C 的数据全部装入内存中运行。

**缺点**

- **进程地址空间不隔离。**由于程序都是直接访问物理内存，所以恶意程序可以随意修改别的进程的内存数据，以达到破坏的目的。有些非恶意的，但是有bug的程序也可能不小心修改了其它程序的内存数据，就会导致其它程序的运行出现异常。这种情况对用户来说是无法容忍的，因为用户希望使用计算机的时候，其中一个任务失败了，至少不能影响其它的任务。

- **内存使用效率低。**在A和B都运行的情况下，如果用户又运行了程序C，而程序C需要20M大小的内存才能运行，而此时系统只剩下8M的空间可供使用，所以此时系统必须在已运行的程序中选择一个将该程序的数据暂时拷贝到硬盘上，释放出部分空间来供程序C使用，然后再将程序C的数据全部装入内存中运行。可以想象得到，在这个过程中，有大量的数据在装入装出，导致效率十分低下。

- **程序运行的地址不确定。**当内存中的剩余空间可以满足程序C的要求后，操作系统会在剩余空间中随机分配一段连续的20M大小的空间给程序C使用，因为是随机分配的，所以程序运行的地址是不确定的。

## 分段

- 按照程序固有的段的大小来划分，每个程序有一个段表（存放着逻辑地址段号和物理地址段号的对应关系）。
- 逻辑地址：段寄存器（段号）+地址寄存器（段内偏移量）

​       为了解决上述问题，人们想到了一种变通的方法，就是增加一个中间层，利用一种间接的地址访问方法访问物理内存。按照这种方法，程序中访问的内存地址不再是实际的物理内存地址，而是一个虚拟地址，然后由操作系统将这个虚拟地址映射到适当的物理内存地址上。这样，只要操作系统处理好虚拟地址到物理内存地址的映射，就可以保证不同的程序最终访问的内存地址位于不同的区域，彼此没有重叠，就可以达到内存地址空间隔离的效果。

​        当创建一个进程时，操作系统会为该进程分配一个4GB大小的虚拟进程地址空间。之所以是4GB，是因为在32位的操作系统中，一个指针长度是4字节，而4字节指针的寻址能力是从0x00000000~0xFFFFFFFF，最大值0xFFFFFFFF表示的即为4GB大小的容量。与虚拟地址空间相对的是一个物理地址空间，这个地址空间对应的是真实的物理内存。如果你的计算机上安装了512M大小的内存，那么这个物理地址空间表示的范围是0x00000000~0x1FFFFFFF。当操作系统做虚拟地址到物理地址映射时，只能映射到这一范围，操作系统也只会映射到这一范围。

​      当进程创建时，每个进程都会有一个自己的4GB虚拟地址空间。要注意的是这个4GB的地址空间是“虚拟”的，并不是真实存在的，而且每个进程只能访问自己虚拟地址空间中的数据，无法访问别的进程中的数据，通过这种方法实现了进程间的地址隔离。那是不是这4GB的虚拟地址空间应用程序可以随意使用呢？很遗憾，在Windows系统下，这个虚拟地址空间被分成了4部分：NULL指针区、用户区、64KB禁入区、内核区。应用程序能使用的只是用户区而已，大约2GB左右(最大可以调整到3GB)。内核区为2GB，内核区保存的是系统线程调度、内存管理、设备驱动等数据，这部分数据供所有的进程共享，但应用程序是不能直接访问的。

​        人们之所以要创建一个虚拟地址空间，目的是为了解决进程地址空间隔离的问题。但程序要想执行，必须运行在真实的内存上，所以，必须在虚拟地址与物理地址间建立一种映射关系。这样，通过映射机制，当程序访问虚拟地址空间上的某个地址值时，就相当于访问了物理地址空间中的另一个值。人们想到了一种分段(Sagmentation)的方法，它的思想是在虚拟地址空间和物理地址空间之间做一一映射。比如说虚拟地址空间中某个10M大小的空间映射到物理地址空间中某个10M大小的空间。这种思想理解起来并不难，操作系统保证不同进程的地址空间被映射到物理地址空间中不同的区域上，这样每个进程最终访问到的物理地址空间都是彼此分开的。通过这种方式，就实现了进程间的地址隔离。还是以实例说明，假设有两个进程A和B，进程A所需内存大小为10M，其虚拟地址空间分布在0x00000000到0x00A00000，进程B所需内存为100M，其虚拟地址空间分布为0x00000000到0x06400000。那么按照分段的映射方法，进程A在物理内存上映射区域为0x00100000到0x00B00000，，进程B在物理内存上映射区域为0x00C00000到0x07000000。于是进程A和进程B分别被映射到了不同的内存区间，彼此互不重叠，实现了地址隔离。从应用程序的角度看来，进程A的地址空间就是分布在0x00000000到0x00A00000，在做开发时，开发人员只需访问这段区间上的地址即可。应用程序并不关心进程A究竟被映射到物理内存的那块区域上了，所以程序的运行地址也就是相当于说是确定的了。 

![2.jpg](https://i.loli.net/2020/04/18/9itzSlpmqOhGxa8.jpg)

​        这种分段的映射方法虽然解决了上述中的问题一和问题三，但并没能解决问题二，即内存的使用效率问题。在分段的映射方法中，每次换入换出内存的都是整个程序，这样会造成大量的磁盘访问操作，导致效率低下。所以这种映射方法还是稍显粗糙，粒度比较大。实际上，程序的运行有局部性特点，在某个时间段内，程序只是访问程序的一小部分数据，也就是说，程序的大部分数据在一个时间段内都不会被用到。

## 分页

​      基于这种情况，人们想到了粒度更小的内存分割和映射方法，这种方法就是分页(Paging)。

​        分页的基本方法是，将地址空间分成许多的页。每页的大小由CPU决定，然后由操作系统选择页的大小。目前Inter系列的CPU支持4KB或4MB的页大小，而PC上目前都选择使用4KB。按这种选择，4GB虚拟地址空间共可以分成1048576（1024*1024）个页，512M的物理内存可以分为131072个页。显然虚拟空间的页数要比物理空间的页数多得多。

​        在分段的方法中，每次程序运行时总是把程序全部装入内存，而分页的方法则有所不同。分页的思想是**程序运行时用到哪页就为哪页分配内存，没用到的页暂时保留在硬盘上**。当用到这些页时再在物理地址空间中为这些页分配内存，然后建立虚拟地址空间中的页和刚分配的物理内存页间的映射。

​       下面通过介绍一个可执行文件的装载过程来说明分页机制的实现方法。一个可执行文件(PE文件)其实就是一些**编译链接好的数据和指令的集合**，它也会被分成很多页，在PE文件执行的过程中，它往内存中装载的单位就是页。当一个PE文件被执行时，操作系统会先为该程序创建一个4GB的进程虚拟地址空间。前面介绍过，虚拟地址空间只是一个中间层而已，它的功能是利用一种映射机制将虚拟地址空间映射到物理地址空间，所以，创建4GB虚拟地址空间其实并不是要真的创建空间，只是要创建那种映射机制所需要的数据结构而已，这种数据结构就是页目和页表。

​        当创建完虚拟地址空间所需要的数据结构后，进程开始读取PE文件的第一页。在PE文件的第一页包含了PE文件头和段表等信息，进程根据文件头和段表等信息，将PE文件中所有的段一一映射到虚拟地址空间中相应的页(PE文件中的段的长度都是页长的整数倍)。这时PE文件的真正指令和数据还没有被装入内存中，操作系统只是根据PE文件的头部等信息建立了PE文件和进程虚拟地址空间中页的映射关系而已。当CPU要访问程序中用到的某个虚拟地址时，当CPU发现该地址并没有相关联的物理地址时，CPU认为该虚拟地址所在的页面是个空页面，CPU会认为这是个页错误(Page Fault)，CPU也就知道了操作系统还未给该PE页面分配内存，CPU会将控制权交还给操作系统。操作系统于是为该PE页面在物理空间中分配一个页面，然后再将这个物理页面与虚拟空间中的虚拟页面映射起来，然后将控制权再还给进程，进程从刚才发生页错误的位置重新开始执行。由于此时已为PE文件的那个页面分配了内存，所以就不会发生页错误了。随着程序的执行，页错误会不断地产生，操作系统也会为进程分配相应的物理页面来满足进程执行的需求。

​        分页方法的核心思想就是当可执行文件执行到第x页时，就为第x页分配一个内存页y，然后再将这个内存页添加到进程虚拟地址空间的映射表中,这个映射表就相当于一个y=f(x)函数。应用程序通过这个映射表就可以访问到x页关联的y页了。

## 缺页中断

​        **虚拟页没有被缓存在物理内存中**（缓存未命中）被称为缺页。

​        当CPU遇见缺页时会触发一个缺页异常，缺页异常将控制权转向操作系统内核，然后调用内核中的缺页异常处理程序，该程序会选择一个牺牲页，如果牺牲页已被修改过，内核会先将它复制回硬盘（采用写回机制而不是直写也是为了尽量减少对硬盘的访问次数），然后再把该虚拟页覆盖到牺牲页的位置，并且更新PTE。

缺页本身是一种中断，与一般的中断一样，需要经过4个处理步骤：

1. 保护CPU现场
2. 分析中断原因
3. 转入缺页中断处理程序进行处理
4. 恢复CPU现场，继续执行

## 虚拟内存实现方式：

（请求分页，请求分段，请求段页式存储管理）

### 请求分页存储管理

​        将虚拟地址内存空间划分位大小相等的页块，同时内存地址空间，也划分位等大小的页块。系统维持一个页表，存储这虚拟页号到物理快块号的映射。程序中的逻辑地址由两部分组成：页号P和页内位移量W。相邻的页面在内存中不一定相邻，即分配给程序的内存块之间不一定连续。逻辑地址转化为物理地址时，根据页表将页号转化为块号，块号乘块大小加上页内偏移得到物理地址。

如果程序执行时，调用到不在内存中的虚拟页面时，发生缺页中断，将页由外存调入内存。如果内存已满，采用页面置换算法将老的淘汰，载入新的。页面置换算法常见的有FIFO,LRU。

- 优点：
  - 没有外碎片，每个内碎片不超过页的大小。
  - 页表简单、长度短、所需硬件少，速度快
  - 主存利用率高于段式。
  - 调入调出速度快，内存管理简单
- 缺点：
  - 程序全部装入内存，要求有相应的硬件支持，如地址变换机构缺页中断的产生和选择淘汰页面等都要求有相应的硬件支持。增加了机器成本和系统开销。
  - 机械分割程序，破坏段的独立性，（可能将一个段分成好几个页）

### 请求分段存储管理：

​       将用户程序地址空间分成若干个大小不等的段，每段能够定义一组相对完整的逻辑信息。如代码段(主程序，子程序，代码库)，数据段（堆段，栈段，已初始化/未初始化对象段）。存储分配时，以段为单位，段内地址连续，段间不连续。虚拟地址由段号和段内地址组成，虚拟地址到实存地址的变换通过段表来实现。 分页对程序猿而言是不可见的。而分段通常对程序猿而言是可见的，因而分段为组织程序和数据提供了方便。

- 优点：

  - 可以分别编写和编译，可以针对不同类型的段采取不同的保护。
  - 可以按段为单位来进行共享，包括通过动态链接进行代码共享。
  - 容易实现以段为单位的存储保护

- 缺点：

  - 各段的长度是任意的，在主存的起点任意，会产生碎片。调入调出速度慢。
  - 段表每行较长，硬件复杂成本高

  - 段间零头大，主存利用率低

### 段页式存储管理

​       段页式存储组织是分段式和分页式结合的存储组织方法。这样可充分利用分段管理和分页管理的长处。 程序的地址空间按逻辑单位分成基本独立的段，而每一段有自己的段名，再把每段分成固定大小的若干页。用分页方法来分配和管理实存。用分段方法来分配和管理虚拟存储器。

- 优点：
  - 段页式管理是段式管理和页式管理相结合而成，具有两者的优点。
- 缺点：
  - 由于管理软件的增加，复杂性和开销也增加。另外需要的硬件以及占用的内存也有所增加，使得执行速度下降。

### 虚拟内存的优点

- 1.在程序需要分配连续的内存空间时，只需要在虚拟内存空间分配连续空间，而不需要在物理内存分配连续的空间，可以利用碎片
- 2.当不同的进程使用同样的代码时，不同的进程可以直接把自己的虚拟内存映射到物理内存即可，节约内存。
- 3.一个系统如果同时运行着很多进程，为各进程分配的内存之和可能会大于实际可用的物理内存，虚拟内存管理使得这种情况下各进程仍然能够正常运行
- 4.虚拟内存管理最主要的作用是让每个进程有独立的地址空间(进程间的安全)



参考自：https://zhuanlan.zhihu.com/p/61238591

## Linux的多级分页

![Picture1.png](https://i.loli.net/2020/04/28/h8F2DdRvfBAraJ1.png)

- **页表的位置**

存放在物理空间中

- **页的大小**

80x86使用 4K 字节固定大小的页面，每个页面均是 4KB

- **页表条目内容**

页表就是一个页表条目（PTE）的数组。页表条目就包括：哪一页，是否在内存，虚拟内存中的地址，物理内存中的地址，在外存中的地址这类信息。

- **一级分页的组成**

对于32位处理器来说，32位的线性地址被分成三部分：页编号（20）+ 页内偏移量（12）

页表项有20位是因为4GB虚拟内存中最多会有20个页。（如果用这种一级页表的方式来编号，必须保障）

页内偏移量有12为是因为2^12=4KB,因为每个页面的大小是4KB。

- **一级分页存在的问题**

为了完成从虚拟地址(线性地址)到物理地址的转换, 操作系统应当为每个任务准备一张页映射表. 因为任务的虚拟地址空间为4GB, 可以分出1048576（2^20）个页, 所以, 映射表需要1048756个表项, 又因为每个表项4B(32位), 故映射表总大小为4MB. 没错, 这张表很大, 要占用相当一部分空间, 考虑到在实践中, 没有哪个任务会真的用到所有表项, 充其量只是很小一部分, 这就很浪费了,为了解决这个问题, 处理器设计了层次化的分页结构.

- **Linux的四级分页**

linux的页表结构是为了节省地址转换所需要的空间。分为PGD/PUD/PMD/PTE，P代表page，G代表global，D代表目录（Director），U代表上级，M代表中间，T代表Table，E代表Entry。PTE是页表项。他们之间的关系是层级结构，通过PGD访问到最低端的PTE，访问方式是上一层地址+偏移量(offset）。PTE+页内偏移量可以访问到具体的物理地址。

- **多级分页的理解**

根据第一级分页根线性地址相应的前几位对上，一级分页指向二级分页，二级分页的前几位都是一样的，然后再依次向下找，好处就是不用一片连续的内存区域，只有少量的页被用到时开销小，但是全部的页都被用到的话，开销就会多一个页表的索引页。